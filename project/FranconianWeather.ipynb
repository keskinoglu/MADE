{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer or Wine: the impact of climate change on Bamberg's vineyards\n",
    "# Research Question\n",
    "### Can Franconia's wine region now include Bamberg due to warmer weather?\n",
    "Despite the negative effects of climate change, some wine varietals thrive in warmer climates. For instance, Bamberg, once a wine-producing region, could potentially regain its status due to rising temperatures. We compare the climate of nearby Würzburg, at the heart of the Franconian winemaking region, to Bamberg's which is currently just outside of the Franconian winemaking region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map of Germany's Winemaknig Regions\n",
    "![Map of Germany's Winemaknig Regions](https://upload.wikimedia.org/wikipedia/commons/8/89/WeinbaugebieteDeutschland.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "We chose to use station data from the Deutscher Wetterdienst (DWD) because it has many direct measures of weather (ex. air temperature 2 meters above ground) and is accurate, easily accessible, and the DWD works to ensure historical data is integrated and well-maintained.\n",
    "\n",
    "The data we'll be using are the following (more information can be found [here](https://wetterdienst.readthedocs.io/en/latest/data/coverage/dwd/observation/monthly.html)):\n",
    "- QN_4 - quality level of the data in the following columns\n",
    "- MO_N - monthly mean of cloud cover\n",
    "- MO_TT - monthly mean of daily temperature means in 2m height\n",
    "- MO_TX - monthly mean of daily temperature maxima in 2m height\n",
    "- MO_TN - monthly mean of daily temperature minima in 2m height\n",
    "- MO_FK - monthly mean of daily wind speed\n",
    "- MX_TX - monthly maximum of daily temperature maxima in 2m height\n",
    "- MX_FX - monthly maximum of daily wind speed\n",
    "- MX_TN - monthly minimum of daily temperature minima in 2m height\n",
    "- MO_SD_S - monthly sum of sunshine duration\n",
    "- QN_6 - quality level of the data in the following columns\n",
    "- MO_RR - monthly sum of precipitation height\n",
    "- MX_RS - monthly maximum of daily precipitation height\n",
    "\n",
    "### Datasource1: Deutscher Wetterdienst (DWD) Station 282 Bamberg\n",
    "* Metadata URL: https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/monthly/kl/historical/DESCRIPTION_obsgermany_climate_monthly_kl_historical_en.pdf\n",
    "* Data URL: https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/monthly/kl/historical/monatswerte_KL_00282_18810101_20231231_hist.zip\n",
    "* Data Type: TXT\n",
    "\n",
    "This data is from the German weather service DWD at node 282 in Bamberg. We'll be using the air temperature monthly aggregate from 1949 - 2024.\n",
    "\n",
    "### Datasource2: Deutscher Wetterdienst (DWD) Station 5705 Würzburg\n",
    "* Metadata URL: https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/monthly/kl/historical/DESCRIPTION_obsgermany_climate_monthly_kl_historical_en.pdf\n",
    "* Data URL: https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/monthly/kl/historical/monatswerte_KL_05705_18810101_20231231_hist.zip\n",
    "* Data Type: TXT\n",
    "\n",
    "This data is from the German weather service DWD at node 5705 in Würzburg. We'll be using the air temperature monthly aggregate from 1949 - 2024.\n",
    "\n",
    "### Data Source License\n",
    "The license information can be found in German [here](https://opendata.dwd.de/LIESMICH.txt) and in English [here](https://www.dwd.de/EN/service/legal_notice/legal_notice.html). The weather data is offered under a [Creative Commons 4.0 license](https://creativecommons.org/licenses/by/4.0/). We will fulfill the obligations to name the data source used in a manner which complies with [these guidelines](https://www.dwd.de/EN/service/legal_notice/templates_dwd_as_source.html?nn=450678)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline\n",
    "### Overview\n",
    "We used Python with the urllib.request library for downloading the dataset from the DWD website, the zipfile library to extract the .txt file from the dowloaded ZIP file, and pandas for temporarily storing and transforming the data.\n",
    "\n",
    "### Transformations\n",
    "The following transformation steps were applied:\n",
    "1. Loading the CSV (in .txt form) into pandas converted data types into appropriate values like int64 and float64\n",
    "2. The \"eor\" (end of record) column was removed as that's not necessary for our purposes.\n",
    "3. Missing or invalid data are marked with -999 in the dataset. We replace these with pd.NA (NA values) since we don't want to be able to compare, numerically, valid and invalid data at all.\n",
    "\n",
    "### Problems\n",
    "We first attempted to use Jayvee to create the pipeline but ran into issues with formatting. Specifically, it was too difficult to remove (especially varying amounts of) preceding whitespace from a text file which separated values by with a character. This also prevented us from changing the value types from string to integer or decimal. We were also unable to chain multiple transformations, making this issue too time consuming to resolve with Jayvee.\n",
    "\n",
    "The issue was resolved when we switched to Python using additional libraries.\n",
    "\n",
    "### Errors and Updates\n",
    "The DWD has a fixed format for files and data, so we don't expect any deviation from the current format unless DWD standards change.\n",
    "\n",
    "We do check to see if the file was downloaded, and the data extracted correctly. If not, the process is halted. It's worthy of note that the DWD also has a standardized file naming structure.\n",
    "\n",
    "The data we are using is updated regularly (at least monthly). No assumptions were made regarding the size of the data we are processing so additional or updated rows should not affect the pipeline negatively. The addition of an entirely new category of data (a new column) would go unused but should not break the pipeline because of how pandas dataframes work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Limitations of the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from FranconianWeather import download_file\n",
    "from FranconianWeather import load_txt_from_zip\n",
    "from FranconianWeather import clean_df\n",
    "from FranconianWeather import save_to_sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully!\n",
      "File downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "bamberg = \"monatswerte_KL_00282_18810101_20231231_hist.zip\"\n",
    "wuerzburg = \"monatswerte_KL_05705_18810101_20231231_hist.zip\"\n",
    "\n",
    "download_file(bamberg)\n",
    "download_file(wuerzburg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the text file inside the zip file\n",
    "bamberg_data_file = \"produkt_klima_monat_18810101_20231231_00282.txt\"\n",
    "\n",
    "# Load the text file into a pandas DataFrame\n",
    "bamberg_df = load_txt_from_zip(bamberg, bamberg_data_file)\n",
    "\n",
    "bamberg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuerzburg_data_file = \"produkt_klima_monat_18810101_20231231_05705.txt\"\n",
    "\n",
    "wuerzburg_df = load_txt_from_zip(wuerzburg, wuerzburg_data_file)\n",
    "\n",
    "wuerzburg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes so we can save to a database\n",
    "combined_df = pd.concat([bamberg_df, wuerzburg_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATIONS_ID</th>\n",
       "      <th>MESS_DATUM_BEGINN</th>\n",
       "      <th>MESS_DATUM_ENDE</th>\n",
       "      <th>QN_4</th>\n",
       "      <th>MO_N</th>\n",
       "      <th>MO_TT</th>\n",
       "      <th>MO_TX</th>\n",
       "      <th>MO_TN</th>\n",
       "      <th>MO_FK</th>\n",
       "      <th>MX_TX</th>\n",
       "      <th>MX_FX</th>\n",
       "      <th>MX_TN</th>\n",
       "      <th>MO_SD_S</th>\n",
       "      <th>QN_6</th>\n",
       "      <th>MO_RR</th>\n",
       "      <th>MX_RS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>282</td>\n",
       "      <td>20131201</td>\n",
       "      <td>20131231</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.03</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.87</td>\n",
       "      <td>11.8</td>\n",
       "      <td>19.6</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>282</td>\n",
       "      <td>19631101</td>\n",
       "      <td>19631130</td>\n",
       "      <td>5</td>\n",
       "      <td>6.25</td>\n",
       "      <td>7.21</td>\n",
       "      <td>10.98</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2.01</td>\n",
       "      <td>18.3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>48.4</td>\n",
       "      <td>5</td>\n",
       "      <td>87.7</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>5705</td>\n",
       "      <td>19421101</td>\n",
       "      <td>19421130</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>282</td>\n",
       "      <td>19441101</td>\n",
       "      <td>19441130</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>97.1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>5705</td>\n",
       "      <td>19610901</td>\n",
       "      <td>19610930</td>\n",
       "      <td>5</td>\n",
       "      <td>4.23</td>\n",
       "      <td>17.46</td>\n",
       "      <td>23.71</td>\n",
       "      <td>12.15</td>\n",
       "      <td>1.56</td>\n",
       "      <td>29.9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.9</td>\n",
       "      <td>192.7</td>\n",
       "      <td>5</td>\n",
       "      <td>34.9</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATIONS_ID  MESS_DATUM_BEGINN  MESS_DATUM_ENDE  QN_4  MO_N  MO_TT  \\\n",
       "1595          282           20131201         20131231     9  <NA>   3.03   \n",
       "994           282           19631101         19631130     5  6.25   7.21   \n",
       "742          5705           19421101         19421130     5  <NA>   <NA>   \n",
       "766           282           19441101         19441130  <NA>  <NA>   <NA>   \n",
       "952          5705           19610901         19610930     5  4.23  17.46   \n",
       "\n",
       "      MO_TX  MO_TN MO_FK MX_TX MX_FX MX_TN MO_SD_S  QN_6 MO_RR MX_RS  \n",
       "1595   5.97   0.29  1.87  11.8  19.6  -5.8    46.0     9  24.2   3.4  \n",
       "994   10.98   3.42  2.01  18.3  <NA>  -2.2    48.4     5  87.7  16.4  \n",
       "742     6.8   <NA>  <NA>  <NA>  <NA>  <NA>    <NA>  <NA>  <NA>  <NA>  \n",
       "766    <NA>   <NA>  <NA>  <NA>  <NA>  <NA>    <NA>     5  97.1  <NA>  \n",
       "952   23.71  12.15  1.56  29.9  <NA>   5.9   192.7     5  34.9  11.6  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove eor column and replace missing and invalid values (-999) with pd.NA.\n",
    "clean_df(combined_df)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to SQLite database successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to an SQLite database\n",
    "save_to_sqlite(combined_df, 'franconian-weather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure and Quality\n",
    "The data is tabularly structured into means of means and extrema (min. and max.) as well as the maximum of extrema by month.\n",
    "\n",
    "We chose to combine both weather stations into a single database for easier storage and loading. It is trivial to split the data again by station ID if need be.\n",
    "\n",
    "Accuracy, completeness, consistency and timeliness is ensured by a trusted institution, the DWD.\n",
    "\n",
    "The data is relevant for the question at hand. However, a major factor which affects the growth of vineyards is soil nutrients. That information is not present in our data.\n",
    "\n",
    "### Output Format\n",
    "The output is formatted as a .sqlite file for long-term storage and wide compatibility. We intend to analyze the data using pandas dataframes.\n",
    "\n",
    "### Reflection and Potential Issues\n",
    "We intend to compare these categories or features between the two datasets and see how much overlap there is.\n",
    "\n",
    "We're conflicted on renaming the columns; on the one hand they are well-defined with precise meanings from DWD but on the other hand one needs to become familiar with this naming convention to work with them effectively.\n",
    "\n",
    "We're also concerned that we'll run into errors when trying to compare periods with missing data. However, because a comparison is not possible, we'll likely drop the rows (months) of the specific columns (features) which cannot be compared. We're unable to do this during the data pipeline because that would create a poorly structured database (some columns will be missing some months that other columns are not missing)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MADE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
